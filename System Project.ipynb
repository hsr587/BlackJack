{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "# Introduction\n",
    "\n",
    "In Assignment 10 for our class, we looked at the use of Q-Learning and DRL learning thorough application to Blackjack (BJ). A Medium article, entitled \"Blackjack, Stocks, and Reinforcement Learning: ML for Risk Management\" [1] was provided for us to review.  For the follwing reasons, I found the assigned article to be dissapointing:\n",
    "1. The results obtained by the author were unrealistic. For Q-learning, the author demonstrated a reward per episode of -68/100, or -68%. For DRL, the author demonstrated an expected return of 643%/100 episode, or +6.43% per episode. Blackjack is a well studied game that is believed to have an optimal strategy adn these values are not consitent with that prior analysis.  Without counting cards or other cheating methods, optimally played BJ has a player expected value of about -0.5%, which implies a house advantage.  Even with cheating, the player EV can only be brought to +1.0%.  This implies\n",
    "2. The Open AI Gym BJ environment has some shortcomings for teaching RL.  First, the output of the environment does not reveal player or dealer cards, making understanding the workings of the model challenging.  Second, the environment only offers a simplified game of BlackJack, which does not have Splits, Doubling Down, or Surrenders incorporated.  This simplified model is useful for implementing RL tests but it also reduced the optimal player EV.\n",
    "3. The assigned article output is challenging to interpret for a few reasons.  First the many images of BJ games are hard to understand and dominate the output.  Second, the author does nto compare his alogithms to any baseline, so performance is diffcult to interpret.\n",
    "\n",
    "\n",
    "To address these concerns, I decided to provide the following:\n",
    "1. A new implmentation of BJ, which allows for\n",
    "2. An analysis of the naive (or random) player for blavkjack\n",
    "3. An analysis of the optimal strategy for Blackjack\n",
    "4. Impletementation of QL and DRL for BJ with comparision to naive and optimal strategies\n",
    "5. An analysis of where the asigned article went wrong.\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 6D Analysis\n",
    "\n",
    "## Decomposition\n",
    "\n",
    "Decomposition of the BJ problem addressed herein is the nature of the project.  The main hypothesis of the project is that QL will produce superior results to DRL as QL is a more exact technique that works in smaller state spaces such as BJ.  We have therefore tested both algorithms and present results.  Additioanlly, by redesigning the BJ environment to allow for a closer look inside the \"black box\", this may allow for more insights as to where the previous effort went wrong.\n",
    "\n",
    "## Domain Expertise\n",
    "\n",
    "This exercise has made me a Domain expert on BJ and optimal strategies.  Aditionally, both literatre and web content provide optimal strategies for the game which can be considered to be the Expert.  The goal of this project is to see how close our created model can come to the Expert but it is not reasonalbe to assume RL techniques will surpuass Expert results.\n",
    "\n",
    "## Data\n",
    "\n",
    "Data for this project comes from the game itself.  No external sources were required.\n",
    "\n",
    "## Design\n",
    "\n",
    "\n",
    "\n",
    "## Diagnosis\n",
    "\n",
    "One purpose of this project is diagnosis of the issues with the assigned article.  Comparision to Expert and naive baselines will allow for detection of\n",
    "\n",
    "## Deployment\n",
    "\n",
    "Although beyond the scope of this article, deployment of this model could be performed by allowing outside users to find optimal plays"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Naive and Expert model assessment"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import utils\n",
    "import blackjack as bj\n",
    "\n",
    "\n",
    "game = bj.Blackjack()\n",
    "#utils.play_bj_random(game)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q Learning Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# DRL Implementation"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Analysis"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from blackjack import Blackjack\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "game = Blackjack()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "data": {
      "text/plain": "('H5', '6', 0, False)"
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game.deal()\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# References\n",
    "\n",
    "1. https://towardsdatascience.com/playing-blackjack-using-model-free-reinforcement-learning-in-google-colab-aa2041a2c13d\n",
    "1. https://trevormcguire.medium.com/blackjack-stocks-and-reinforcement-learning-ea4014115aeb\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Envrionment packages\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import gym"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hrose/PycharmProjects/BlackJack/venv/lib/python3.10/site-packages/gym/core.py:329: DeprecationWarning: \u001B[33mWARN: Initializing wrapper in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n",
      "/Users/hrose/PycharmProjects/BlackJack/venv/lib/python3.10/site-packages/gym/wrappers/step_api_compatibility.py:39: DeprecationWarning: \u001B[33mWARN: Initializing environment in old step API which returns one bool instead of two. It is recommended to set `new_step_api=True` to use new step API. This will be the default behaviour in future.\u001B[0m\n",
      "  deprecation(\n"
     ]
    }
   ],
   "source": [
    "env = gym.make(\"Blackjack-v1\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "(12, 5, False)"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "outputs": [
    {
     "data": {
      "text/plain": "((15, 4, False), -1.0, True, {})"
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()\n",
    "env.step(0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "outputs": [
    {
     "data": {
      "text/plain": "'Blackjack-v1'"
     },
     "execution_count": 328,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.spec.id"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, state_size = 3, action_size = 2):\n",
    "        super(DQN, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, action_size)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        return self.fc3(x)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "outputs": [],
   "source": [
    "net = DQN()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "outputs": [
    {
     "data": {
      "text/plain": "array([1, 2, 3])"
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "test_in = np.array([1,2,3])\n",
    "test_in"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [
    {
     "data": {
      "text/plain": "(3,)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[27], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mnet\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtest_in\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mshape\n",
      "File \u001B[0;32m~/PycharmProjects/BlackJack/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "Cell \u001B[0;32mIn[6], line 9\u001B[0m, in \u001B[0;36mDQN.forward\u001B[0;34m(self, state)\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, state):\n\u001B[0;32m----> 9\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mstate\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[1;32m     10\u001B[0m     x \u001B[38;5;241m=\u001B[39m F\u001B[38;5;241m.\u001B[39mrelu(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x))\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc3(x)\n",
      "File \u001B[0;32m~/PycharmProjects/BlackJack/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1190\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *input, **kwargs)\u001B[0m\n\u001B[1;32m   1186\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1187\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1188\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1189\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1190\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1191\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1192\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/PycharmProjects/BlackJack/venv/lib/python3.10/site-packages/torch/nn/modules/linear.py:114\u001B[0m, in \u001B[0;36mLinear.forward\u001B[0;34m(self, input)\u001B[0m\n\u001B[1;32m    113\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 114\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlinear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbias\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mTypeError\u001B[0m: linear(): argument 'input' (position 1) must be Tensor, not numpy.ndarray"
     ]
    }
   ],
   "source": [
    "net(test_in).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.1954,  1.1420, -0.0674],\n        [ 0.9946, -0.3488, -0.5642]])"
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 3])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_in.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([2, 2])"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(test_in).shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "outputs": [
    {
     "data": {
      "text/plain": "0.7730318168810721"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [
    {
     "data": {
      "text/plain": "0.32557896658185126"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.random()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "from collections import deque, namedtuple\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [],
   "source": [
    "d = deque(maxlen=3)\n",
    "d.append(1)\n",
    "d.append(2)\n",
    "d.append(3)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "outputs": [
    {
     "data": {
      "text/plain": "deque([1, 2, 3], maxlen=3)"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "d.append(4)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "outputs": [
    {
     "data": {
      "text/plain": "deque([2, 3, 4], maxlen=3)"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "data": {
      "text/plain": "deque([Transition(state=tensor([1, 2]), action=2, next_state=3, reward=tensor([3, 4]), done=5),\n       Transition(state=tensor([1, 3]), action=7, next_state=8, reward=tensor([3, 5]), done=10),\n       Transition(state=tensor([1, 4]), action=12, next_state=13, reward=tensor([3, 6]), done=15)],\n      maxlen=3)"
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Transition = namedtuple('Transition', ('state', 'action', 'next_state', 'reward', 'done'))\n",
    "\n",
    "\n",
    "class ReplayMemory():\n",
    "    \"\"\"\n",
    "    Class to create memory for DQN training\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque(maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"\n",
    "        Method to allow a Transition to be added to the deque.\n",
    "        :param args: arguments for adding to a Transition named tuple to be added to the list\n",
    "                        should be state, action, reward, next_state, done where:\n",
    "                        state: tensor, action: int, reward: float, next_state: tensor, done: bool\n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        \"\"\"\n",
    "        Method to return batch of Transitions randomly selected without replacement.\n",
    "        :param batch_size: int - Length of batch\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        s =  random.sample(self.memory, batch_size)\n",
    "        batches = Transition(*zip(*s))\n",
    "        return batches\n",
    "\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n",
    "\n",
    "mem = ReplayMemory(3)\n",
    "mem.push(torch.tensor([1,2]),2,3,torch.tensor([3,4]),5)\n",
    "mem.push(torch.tensor([1,3]),7,8,torch.tensor([3,5]),10)\n",
    "mem.push(torch.tensor([1,4]), 12, 13, torch.tensor([3,6]), 15)\n",
    "mem.memory"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 2])"
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "can't set attribute",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[81], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mmem\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msample\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m2\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[76], line 30\u001B[0m, in \u001B[0;36mReplayMemory.sample\u001B[0;34m(self, batch_size)\u001B[0m\n\u001B[1;32m     28\u001B[0m s \u001B[38;5;241m=\u001B[39m  random\u001B[38;5;241m.\u001B[39msample(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmemory, batch_size)\n\u001B[1;32m     29\u001B[0m batches \u001B[38;5;241m=\u001B[39m Transition(\u001B[38;5;241m*\u001B[39m\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39ms))\n\u001B[0;32m---> 30\u001B[0m \u001B[43mbatches\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstate\u001B[49m \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(batches\u001B[38;5;241m.\u001B[39mstate)\n\u001B[1;32m     31\u001B[0m batches\u001B[38;5;241m.\u001B[39mnew_state \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39mstack(batches\u001B[38;5;241m.\u001B[39mnew_state)\n\u001B[1;32m     32\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m batches\n",
      "\u001B[0;31mAttributeError\u001B[0m: can't set attribute"
     ]
    }
   ],
   "source": [
    "mem.sample(2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor([1, 2, 3]), tensor([4, 5, 6]), tensor([1, 2, 3]), tensor([4, 5, 6]))"
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (torch.tensor([1,2,3]), torch.tensor([4,5,6]))\n",
    "\n",
    "a+b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1, 2, 3],\n        [4, 5, 6]])"
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = torch.stack(a)\n",
    "b"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([3, 1])"
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = (1, 2, 3)\n",
    "d = torch.tensor(c).unsqueeze(1)\n",
    "d.size()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[-0.6338,  0.4557],\n        [-1.5007, -1.0967],\n        [ 0.7038,  0.1803],\n        [-0.6902, -0.6281],\n        [-0.5288,  2.0306],\n        [ 1.1666, -0.4851],\n        [-0.2686, -0.3346],\n        [ 0.3593, -0.8970],\n        [-0.5768,  1.0790],\n        [-0.4323, -0.3424]])"
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn([10, 2])\n",
    "a"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "outputs": [
    {
     "data": {
      "text/plain": "torch.return_types.max(\nvalues=tensor([[ 0.4557],\n        [-1.0967],\n        [ 0.7038],\n        [-0.6281],\n        [ 2.0306],\n        [ 1.1666],\n        [-0.2686],\n        [ 0.3593],\n        [ 1.0790],\n        [-0.3424]]),\nindices=tensor([[1],\n        [1],\n        [0],\n        [1],\n        [1],\n        [0],\n        [0],\n        [0],\n        [1],\n        [1]]))"
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(1, keepdim=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[1],\n        [1],\n        [0],\n        [1],\n        [1],\n        [0],\n        [0],\n        [0],\n        [1],\n        [1]])"
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = a.max(1, keepdim=True).indices\n",
    "index"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[0],\n        [0],\n        [1],\n        [0],\n        [0],\n        [1],\n        [1],\n        [1],\n        [0],\n        [0]])"
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1-index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([[ 0.4557],\n        [-1.0967],\n        [ 0.7038],\n        [-0.6281],\n        [ 2.0306],\n        [ 1.1666],\n        [-0.2686],\n        [ 0.3593],\n        [ 1.0790],\n        [-0.3424]])"
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.gather(a, 1, index)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([1, 0, 1])"
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f = torch.tensor([True, False, True], dtype=int)\n",
    "f"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[122], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43menv\u001B[49m\u001B[38;5;241m.\u001B[39mreset()\n",
      "\u001B[0;31mNameError\u001B[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "env.reset()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
